{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faac2b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Setup\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import pathlib, os, sys, operator, re, datetime\n",
    "\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Model\n",
    "import tensorflow_datasets as tfds\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3f0699",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2018 = 'p:\\Mitchell\\FFNeuralNetwork\\stats2018.csv'\n",
    "data2019 = 'p:\\Mitchell\\FFNeuralNetwork\\stats2019.csv'\n",
    "data2020 = 'p:\\Mitchell\\FFNeuralNetwork\\stats2020.csv'\n",
    "data2021 = 'p:\\Mitchell\\FFNeuralNetwork\\stats2021.csv'\n",
    "data2022 = 'p:\\Mitchell\\FFNeuralNetwork\\stats2022.csv'\n",
    "data2023 = 'p:\\Mitchell\\FFNeuralNetwork\\stats2023.csv'\n",
    "data2024 = 'p:\\Mitchell\\FFNeuralNetwork\\stats2024.csv'\n",
    "\n",
    "rank2018 = pd.read_csv(data2018)\n",
    "H_2018 = rank2018.shape[0]\n",
    "finish_2018 = np.array([H_2018])\n",
    "finish_2018 = rank2018[\"Column2\"]\n",
    "\n",
    "rank2019 = pd.read_csv(data2019)\n",
    "H_2019 = rank2019.shape[0]\n",
    "finish_2019 = np.array([H_2019])\n",
    "finish_2019 = rank2019[\"Column2\"]\n",
    "\n",
    "rank2020 = pd.read_csv(data2020)\n",
    "H_2020 = rank2020.shape[0]\n",
    "finish_2020 = np.array([H_2020])\n",
    "finish_2020 = rank2020[\"Column2\"]\n",
    "\n",
    "rank2021 = pd.read_csv(data2021)\n",
    "H_2021 = rank2021.shape[0]\n",
    "finish_2021 = np.array([H_2021])\n",
    "finish_2021 = rank2021[\"Column2\"]\n",
    "\n",
    "rank2022 = pd.read_csv(data2022)\n",
    "H_2022 = rank2022.shape[0]\n",
    "finish_2022 = np.array([H_2022])\n",
    "finish_2022 = rank2022[\"Column2\"]\n",
    "\n",
    "rank2023 = pd.read_csv(data2023)\n",
    "H_2023 = rank2023.shape[0]\n",
    "finish_2023 = np.array([H_2023])\n",
    "finish_2023 = rank2023[\"Column2\"]\n",
    "\n",
    "rank2024 = pd.read_csv(data2024)\n",
    "H_2024 = rank2024.shape[0]\n",
    "finish_2024 = np.array([H_2024])\n",
    "finish_2024 = rank2024[\"Column2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "184e6d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "update2024 = np.empty((0,0))\n",
    "print(update2024)\n",
    "for h in range(2, H_2024):\n",
    "    player2024 = finish_2024[h]\n",
    "    for i in range(2, H_2023):\n",
    "        player2023 = finish_2023[i]\n",
    "        if(player2024 == player2023):\n",
    "            update2024 = np.append(update2024, [i-1])\n",
    "            break\n",
    "        if(i == H_2023 -1):\n",
    "            update2024 = np.append(update2024, [0])\n",
    "\n",
    "update2023 = np.empty((0,0))\n",
    "print(update2023)\n",
    "for h in range(2, H_2023):\n",
    "    player2023 = finish_2023[h]\n",
    "    for i in range(2, H_2022):\n",
    "        player2022 = finish_2022[i]\n",
    "        if(player2023 == player2022):\n",
    "            update2023 = np.append(update2023, [i-1])\n",
    "            break\n",
    "        if(i == H_2022 -1):\n",
    "            update2023 = np.append(update2023, [0])\n",
    "\n",
    "update2022 = np.empty((0,0))\n",
    "print(update2022)\n",
    "for h in range(2, H_2022):\n",
    "    player2022 = finish_2022[h]\n",
    "    for i in range(2, H_2021):\n",
    "        player2021 = finish_2021[i]\n",
    "        if(player2022 == player2021):\n",
    "            update2022 = np.append(update2022, [i-1])\n",
    "            break\n",
    "        if(i == H_2021 -1):\n",
    "            update2022 = np.append(update2022, [0])\n",
    "\n",
    "update2021 = np.empty((0,0))\n",
    "print(update2021)\n",
    "for h in range(2, H_2021):\n",
    "    player2021 = finish_2021[h]\n",
    "    for i in range(2, H_2020):\n",
    "        player2020 = finish_2020[i]\n",
    "        if(player2021 == player2020):\n",
    "            update2021 = np.append(update2021, [i-1])\n",
    "            break\n",
    "        if(i == H_2020 -1):\n",
    "            update2021 = np.append(update2021, [0])\n",
    "\n",
    "update2020 = np.empty((0,0))\n",
    "print(update2020)\n",
    "for h in range(2, H_2020):\n",
    "    player2020 = finish_2020[h]\n",
    "    for i in range(2, H_2019):\n",
    "        player2019 = finish_2019[i]\n",
    "        if(player2020 == player2019):\n",
    "            update2020 = np.append(update2020, [i-1])\n",
    "            break\n",
    "        if(i == H_2019 -1):\n",
    "            update2020 = np.append(update2020, [0])\n",
    "\n",
    "update2019 = np.empty((0,0))\n",
    "print(update2019)\n",
    "for h in range(2, H_2019):\n",
    "    player2019 = finish_2019[h]\n",
    "    for i in range(2, H_2018):\n",
    "        player2018 = finish_2018[i]\n",
    "        if(player2019 == player2018):\n",
    "            update2019 = np.append(update2019, [i-1])\n",
    "            break\n",
    "        if(i == H_2018 -1):\n",
    "            update2019 = np.append(update2019, [0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c6624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2024 = pd.DataFrame(update2024)\n",
    "# df2024.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2024\")\n",
    "# df2023 = pd.DataFrame(update2023)\n",
    "# df2023.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2023\")\n",
    "# df2022 = pd.DataFrame(update2022)\n",
    "# df2022.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2022\")\n",
    "# df2021 = pd.DataFrame(update2021)\n",
    "# df2021.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2021\")\n",
    "# df2020 = pd.DataFrame(update2020)\n",
    "# df2020.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2020\")\n",
    "# df2019 = pd.DataFrame(update2019)\n",
    "# df2019.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3652b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3246, 1, 19)\n",
      "[[0.00155279]\n",
      " [0.00310559]\n",
      " [0.00465839]\n",
      " ...\n",
      " [0.9968355 ]\n",
      " [0.99841774]\n",
      " [1.        ]]\n"
     ]
    }
   ],
   "source": [
    "data = 'p:\\Mitchell\\FFNeuralNetwork\\statsTraining.csv'\n",
    "dataAns = 'p:\\Mitchell\\FFNeuralNetwork\\statsAnswer.csv'\n",
    "\n",
    "Smalldata = 'p:\\Mitchell\\FFNeuralNetwork\\SmallBatchTraining.csv'\n",
    "SmalldataAns = 'p:\\Mitchell\\FFNeuralNetwork\\SmallBatchTrainingAns.csv'\n",
    "\n",
    "regular = True \n",
    "\n",
    "if(regular):\n",
    "    df = pd.read_csv(data)\n",
    "    df_y = pd.read_csv(dataAns)\n",
    "\n",
    "    numpy_array = df.to_numpy()\n",
    "    numpy_array = numpy_array[:, np.newaxis, :]\n",
    "    numpy_size = numpy_array.size\n",
    "\n",
    "    numpy_array_two = df_y.to_numpy()\n",
    "    numpy_array_two = numpy_array_two.astype(np.float32)\n",
    "\n",
    "    numpy_array[np.isnan(numpy_array)] = 0\n",
    "    numpy_array_test = numpy_array.astype(np.float32)\n",
    "\n",
    "    # print(numpy_array)\n",
    "    # print(numpy_size)\n",
    "    # print(numpy_array.shape)\n",
    "    # print(numpy_array_two.shape)\n",
    "else:\n",
    "    df = pd.read_csv(Smalldata)\n",
    "    df_y = pd.read_csv(SmalldataAns)\n",
    "\n",
    "    numpy_array = df.to_numpy()\n",
    "    numpy_array = numpy_array[:, np.newaxis, :]\n",
    "    numpy_size = numpy_array.size\n",
    "\n",
    "    numpy_array_two = df_y.to_numpy()\n",
    "    numpy_array_two = numpy_array_two.astype(np.float32)\n",
    "\n",
    "    numpy_array[np.isnan(numpy_array)] = 0\n",
    "    numpy_array_test = numpy_array.astype(np.float32)\n",
    "\n",
    "    # print(numpy_array)\n",
    "    # print(numpy_size)\n",
    "    # print(numpy_array.shape)\n",
    "    # print(numpy_array_two.shape) \n",
    "\n",
    "H = numpy_array.shape[0]\n",
    "W = numpy_array.shape[1]\n",
    "\n",
    "H2 = numpy_array_two.shape[0]\n",
    "W2 = numpy_array_two.shape[1]\n",
    "\n",
    "numpy_array = numpy_array/100\n",
    "numpy_array_two = numpy_array_two\n",
    "\n",
    "print(numpy_array.shape)\n",
    "# print(numpy_array)   \n",
    "print(numpy_array_two)   \n",
    "\n",
    "# print(H)\n",
    "# print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5096ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630, 1, 19)\n"
     ]
    }
   ],
   "source": [
    "Testdata = 'p:\\Mitchell\\FFNeuralNetwork\\statsTesting.csv'\n",
    "TestdataAns = 'p:\\Mitchell\\FFNeuralNetwork\\statsTestAnswer.csv'\n",
    "\n",
    "SmallTestdata = 'p:\\Mitchell\\FFNeuralNetwork\\SmallBatchTest.csv'\n",
    "SmallTestdataAns = 'p:\\Mitchell\\FFNeuralNetwork\\SmallBatchTestAns.csv'\n",
    "\n",
    "regular = True \n",
    "\n",
    "if(regular):\n",
    "    Testdf = pd.read_csv(Testdata)\n",
    "    Testdf_y = pd.read_csv(TestdataAns)\n",
    "\n",
    "    numpy_array_test = Testdf.to_numpy()\n",
    "    numpy_array_test = numpy_array_test[:, np.newaxis, :]\n",
    "    numpy_sizeT = numpy_array_test.size\n",
    "\n",
    "    numpy_array_ans = Testdf_y.to_numpy()\n",
    "    numpy_array_ans = numpy_array_ans.astype(np.float32)\n",
    "\n",
    "    numpy_array_test[np.isnan(numpy_array_test)] = 0\n",
    "    numpy_array_test = numpy_array_test.astype(np.float32)\n",
    "else:\n",
    "    Testdf = pd.read_csv(SmallTestdata)\n",
    "    Testdf_y = pd.read_csv(SmallTestdataAns)\n",
    "\n",
    "    numpy_array_test = Testdf.to_numpy()\n",
    "    numpy_array_test = numpy_array_test[:, np.newaxis, :]\n",
    "    numpy_sizeT = numpy_array_test.size\n",
    "\n",
    "    numpy_array_ans = Testdf_y.to_numpy()\n",
    "    numpy_array_ans = numpy_array_ans.astype(np.float32)\n",
    "\n",
    "    numpy_array_test[np.isnan(numpy_array_test)] = 0\n",
    "    numpy_array_test = numpy_array_test.astype(np.float32)\n",
    "\n",
    "\n",
    "HT = numpy_array_test.shape[0]\n",
    "WT = numpy_array_test.shape[1]\n",
    "\n",
    "HT2 = numpy_array_ans.shape[0]\n",
    "WT2 = numpy_array_ans.shape[1]\n",
    "\n",
    "numpy_array_test = numpy_array_test/100\n",
    "numpy_array_ans = numpy_array_ans/(numpy_array_ans.size)\n",
    "    \n",
    "print(numpy_array_test.shape)\n",
    "# print(numpy_array_test)\n",
    "# print(numpy_array_ans)\n",
    "\n",
    "# print(H)\n",
    "# print(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8918 - loss: 0.3636 - val_accuracy: 0.9660 - val_loss: 0.1109\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.0978 - val_accuracy: 0.9752 - val_loss: 0.0836\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0660 - val_accuracy: 0.9770 - val_loss: 0.0770\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0528 - val_accuracy: 0.9804 - val_loss: 0.0667\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0425 - val_accuracy: 0.9776 - val_loss: 0.0717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ad95731810>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow Example\n",
    "\n",
    "\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28), name='layers_input'),\n",
    "    tf.keras.layers.Flatten(name='layers_flatten'),\n",
    "    tf.keras.layers.Dense(512, activation='relu', name='layers_dense'),\n",
    "    tf.keras.layers.Dropout(0.2, name='layers_dropout'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name='layers_dense_2')\n",
    "  ])\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f7b219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3297 - val_loss: 0.3331\n",
      "Epoch 2/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3314 - val_loss: 0.3331\n",
      "Epoch 3/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3370 - val_loss: 0.3331\n",
      "Epoch 4/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3407 - val_loss: 0.3331\n",
      "Epoch 5/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3287 - val_loss: 0.3331\n",
      "Epoch 6/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3276 - val_loss: 0.3331\n",
      "Epoch 7/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3322 - val_loss: 0.3331\n",
      "Epoch 8/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3370 - val_loss: 0.3331\n",
      "Epoch 9/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3404 - val_loss: 0.3331\n",
      "Epoch 10/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3309 - val_loss: 0.3331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2873ef02010>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  # tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1000, activation='softmax')\n",
    "])\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#   loss='sparse_categorical_crossentropy',\n",
    "#   metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "  loss='mean_squared_error')\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# print(numpy_array[1,0])\n",
    "# model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "model.fit(numpy_array, numpy_array_two, epochs=10, validation_data=(numpy_array_test, numpy_array_ans), callbacks=[tensorboard_callback])\n",
    "# model.evaluate(numpy_array_test, numpy_array_ans, verbose = 2)\n",
    "\n",
    "# python -m tensorboard.main --logdir=logs/fit\n",
    "\n",
    "# Use above to view data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a44aa691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 23)\n"
     ]
    }
   ],
   "source": [
    "# Generate some dummy input data\n",
    "# dummy_input = tf.random.normal((1, 1, 28))\n",
    "\n",
    "data = [2.700e-01, 1.600e-01, 1.600e-01, 0.000e+00, 0.000e+00, 0.000e+00,\n",
    "0.000e+00, 0.000e+00, 3.450e+00, 2.005e+01, 5.810e-02, 1.300e-01, 4.300e-01,\n",
    "3.300e-01, 2.780e+00, 8.420e-02, 2.000e-02, 2.000e-02, 1.000e-02,\n",
    "1.500e-01, 3.220e+00, 3.553e+00, 4.300e-01]\n",
    "input = np.array(data)        \n",
    "reshaped_single_sample = input.reshape(1, -1) # Reshapes to (1, number_of_features)\n",
    "print(reshaped_single_sample.shape)\n",
    "\n",
    "# Get the output of the final layer\n",
    "# final_layer_output = model.predict(reshaped_single_sample)\n",
    "# print(reshaped_single_sample)\n",
    "# final_layer_output = final_layer_output*100\n",
    "# print(final_layer_output)\n",
    "\n",
    "# smallest = final_layer_output[0]\n",
    "# for val in final_layer_output:\n",
    "#     if val < smallest:\n",
    "#         smallest = val\n",
    "# print(smallest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
