{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faac2b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Setup\n",
    "\n",
    "import pathlib, os, sys, operator, re, datetime\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras import Model\n",
    "import tensorflow_datasets as tfds\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b3f0699",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2018 = 'p:\\Mitchell\\stats2018.csv'\n",
    "data2019 = 'p:\\Mitchell\\stats2019.csv'\n",
    "data2020 = 'p:\\Mitchell\\stats2020.csv'\n",
    "data2021 = 'p:\\Mitchell\\stats2021.csv'\n",
    "data2022 = 'p:\\Mitchell\\stats2022.csv'\n",
    "data2023 = 'p:\\Mitchell\\stats2023.csv'\n",
    "data2024 = 'p:\\Mitchell\\stats2024.csv'\n",
    "\n",
    "rank2018 = pd.read_csv(data2018)\n",
    "H_2018 = rank2018.shape[0]\n",
    "finish_2018 = np.array([H_2018])\n",
    "finish_2018 = rank2018[\"Column2\"]\n",
    "\n",
    "rank2019 = pd.read_csv(data2019)\n",
    "H_2019 = rank2019.shape[0]\n",
    "finish_2019 = np.array([H_2019])\n",
    "finish_2019 = rank2019[\"Column2\"]\n",
    "\n",
    "rank2020 = pd.read_csv(data2020)\n",
    "H_2020 = rank2020.shape[0]\n",
    "finish_2020 = np.array([H_2020])\n",
    "finish_2020 = rank2020[\"Column2\"]\n",
    "\n",
    "rank2021 = pd.read_csv(data2021)\n",
    "H_2021 = rank2021.shape[0]\n",
    "finish_2021 = np.array([H_2021])\n",
    "finish_2021 = rank2021[\"Column2\"]\n",
    "\n",
    "rank2022 = pd.read_csv(data2022)\n",
    "H_2022 = rank2022.shape[0]\n",
    "finish_2022 = np.array([H_2022])\n",
    "finish_2022 = rank2022[\"Column2\"]\n",
    "\n",
    "rank2023 = pd.read_csv(data2023)\n",
    "H_2023 = rank2023.shape[0]\n",
    "finish_2023 = np.array([H_2023])\n",
    "finish_2023 = rank2023[\"Column2\"]\n",
    "\n",
    "rank2024 = pd.read_csv(data2024)\n",
    "H_2024 = rank2024.shape[0]\n",
    "finish_2024 = np.array([H_2024])\n",
    "finish_2024 = rank2024[\"Column2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "184e6d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "update2024 = np.empty((0,0))\n",
    "print(update2024)\n",
    "for h in range(2, H_2024):\n",
    "    player2024 = finish_2024[h]\n",
    "    for i in range(2, H_2023):\n",
    "        player2023 = finish_2023[i]\n",
    "        if(player2024 == player2023):\n",
    "            update2024 = np.append(update2024, [i-1])\n",
    "            break\n",
    "        if(i == H_2023 -1):\n",
    "            update2024 = np.append(update2024, [0])\n",
    "\n",
    "update2023 = np.empty((0,0))\n",
    "print(update2023)\n",
    "for h in range(2, H_2023):\n",
    "    player2023 = finish_2023[h]\n",
    "    for i in range(2, H_2022):\n",
    "        player2022 = finish_2022[i]\n",
    "        if(player2023 == player2022):\n",
    "            update2023 = np.append(update2023, [i-1])\n",
    "            break\n",
    "        if(i == H_2022 -1):\n",
    "            update2023 = np.append(update2023, [0])\n",
    "\n",
    "update2022 = np.empty((0,0))\n",
    "print(update2022)\n",
    "for h in range(2, H_2022):\n",
    "    player2022 = finish_2022[h]\n",
    "    for i in range(2, H_2021):\n",
    "        player2021 = finish_2021[i]\n",
    "        if(player2022 == player2021):\n",
    "            update2022 = np.append(update2022, [i-1])\n",
    "            break\n",
    "        if(i == H_2021 -1):\n",
    "            update2022 = np.append(update2022, [0])\n",
    "\n",
    "update2021 = np.empty((0,0))\n",
    "print(update2021)\n",
    "for h in range(2, H_2021):\n",
    "    player2021 = finish_2021[h]\n",
    "    for i in range(2, H_2020):\n",
    "        player2020 = finish_2020[i]\n",
    "        if(player2021 == player2020):\n",
    "            update2021 = np.append(update2021, [i-1])\n",
    "            break\n",
    "        if(i == H_2020 -1):\n",
    "            update2021 = np.append(update2021, [0])\n",
    "\n",
    "update2020 = np.empty((0,0))\n",
    "print(update2020)\n",
    "for h in range(2, H_2020):\n",
    "    player2020 = finish_2020[h]\n",
    "    for i in range(2, H_2019):\n",
    "        player2019 = finish_2019[i]\n",
    "        if(player2020 == player2019):\n",
    "            update2020 = np.append(update2020, [i-1])\n",
    "            break\n",
    "        if(i == H_2019 -1):\n",
    "            update2020 = np.append(update2020, [0])\n",
    "\n",
    "update2019 = np.empty((0,0))\n",
    "print(update2019)\n",
    "for h in range(2, H_2019):\n",
    "    player2019 = finish_2019[h]\n",
    "    for i in range(2, H_2018):\n",
    "        player2018 = finish_2018[i]\n",
    "        if(player2019 == player2018):\n",
    "            update2019 = np.append(update2019, [i-1])\n",
    "            break\n",
    "        if(i == H_2018 -1):\n",
    "            update2019 = np.append(update2019, [0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2c6624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2024 = pd.DataFrame(update2024)\n",
    "# df2024.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2024\")\n",
    "# df2023 = pd.DataFrame(update2023)\n",
    "# df2023.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2023\")\n",
    "# df2022 = pd.DataFrame(update2022)\n",
    "# df2022.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2022\")\n",
    "# df2021 = pd.DataFrame(update2021)\n",
    "# df2021.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2021\")\n",
    "# df2020 = pd.DataFrame(update2020)\n",
    "# df2020.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2020\")\n",
    "# df2019 = pd.DataFrame(update2019)\n",
    "# df2019.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3652b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74658\n",
      "(3246, 1, 23)\n",
      "(3246, 1)\n"
     ]
    }
   ],
   "source": [
    "data = 'p:\\Mitchell\\statsTraining.csv'\n",
    "dataAns = 'p:\\Mitchell\\statsAnswer.csv'\n",
    "\n",
    "df = pd.read_csv(data)\n",
    "df_y = pd.read_csv(dataAns)\n",
    "\n",
    "numpy_array = df.to_numpy()\n",
    "numpy_array = numpy_array[:, np.newaxis, :]\n",
    "numpy_size = numpy_array.size\n",
    "\n",
    "numpy_array_two = df_y.to_numpy()\n",
    "numpy_array_two = numpy_array_two.astype(np.float32)\n",
    "\n",
    "numpy_array[np.isnan(numpy_array)] = 0\n",
    "numpy_array_test = numpy_array.astype(np.float32)\n",
    "\n",
    "# print(numpy_array)\n",
    "print(numpy_size)\n",
    "print(numpy_array.shape)\n",
    "print(numpy_array_two.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5096ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testdata = 'p:\\Mitchell\\statsTesting.csv'\n",
    "TestdataAns = 'p:\\Mitchell\\statsTestAnswer.csv'\n",
    "\n",
    "Testdf = pd.read_csv(Testdata)\n",
    "Testdf_y = pd.read_csv(TestdataAns)\n",
    "\n",
    "numpy_array_test = Testdf.to_numpy()\n",
    "numpy_array_test = numpy_array_test[:, np.newaxis, :]\n",
    "numpy_sizeT = numpy_array_test.size\n",
    "\n",
    "numpy_array_ans = Testdf_y.to_numpy()\n",
    "numpy_array_ans = numpy_array_ans.astype(np.float32)\n",
    "\n",
    "numpy_array_test[np.isnan(numpy_array_test)] = 0\n",
    "numpy_array_test = numpy_array_test.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cf0ae4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3246, 1, 23)\n"
     ]
    }
   ],
   "source": [
    "H = numpy_array.shape[0]\n",
    "W = numpy_array.shape[1]\n",
    "\n",
    "H2 = numpy_array_two.shape[0]\n",
    "W2 = numpy_array_two.shape[1]\n",
    "\n",
    "numpy_array = numpy_array/100\n",
    "numpy_array_two = numpy_array_two/100\n",
    " \n",
    "print(numpy_array.shape)\n",
    "# print(numpy_array)   \n",
    "\n",
    "# print(H)\n",
    "# print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f0c4b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630, 1, 23)\n"
     ]
    }
   ],
   "source": [
    "HT = numpy_array_test.shape[0]\n",
    "WT = numpy_array_test.shape[1]\n",
    "\n",
    "HT2 = numpy_array_ans.shape[0]\n",
    "WT2 = numpy_array_ans.shape[1]\n",
    "\n",
    "numpy_array_test = numpy_array_test/100\n",
    "numpy_array_ans = numpy_array_ans/100\n",
    "    \n",
    "print(numpy_array_test.shape)\n",
    "# print(numpy_array_test)\n",
    "\n",
    "# print(H)\n",
    "# print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5f7b219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 6.8081e-04 - loss: 4.9079\n",
      "Epoch 2/6\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0023 - loss: 1.7757\n",
      "Epoch 3/6\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 7.8333e-04 - loss: 1.3030\n",
      "Epoch 4/6\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0016 - loss: 1.1413  \n",
      "Epoch 5/6\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0032 - loss: 1.0576\n",
      "Epoch 6/6\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0050 - loss: 0.9644\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0020 - loss: 0.5747     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.795696496963501, 0.0031746032182127237]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow Example\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(numpy_array.shape)\n",
    "# print(numpy_array_two.shape)\n",
    "# print(numpy_array_test.shape)\n",
    "# print(numpy_array_ans.shape)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  # tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(700, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "# print(numpy_array[1,0])\n",
    "# model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "model.fit(numpy_array, numpy_array_two, epochs=6)\n",
    "model.evaluate(numpy_array_test, numpy_array_ans, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a44aa691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "[[2.700e-01 1.600e-01 1.600e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 3.450e+00 2.005e+01 5.810e-02 1.300e-01 4.300e-01 3.300e-01\n",
      "  2.780e+00 8.420e-02 2.000e-02 2.000e-02 1.000e-02 1.500e-01 3.220e+00\n",
      "  3.553e+00 4.300e-01]]\n",
      "[[0.06246151 0.60725003 0.10310328 0.05494081 0.07828061 0.31371957\n",
      "  0.24892746 0.16139713 0.03745814 0.04819423 0.2886606  0.12832457\n",
      "  0.15517534 0.08679902 0.08067209 0.24138701 0.05074739 0.07108968\n",
      "  0.13653825 0.0135745  0.06815831 0.1570457  0.05165043 0.19850959\n",
      "  0.42246372 0.11103845 0.20485641 0.02843635 0.03366656 0.07244324\n",
      "  0.08133971 0.12468489 0.05835895 0.0208024  0.3579074  0.1045121\n",
      "  0.22665358 0.12919444 0.13918227 0.20991507 0.10511703 0.05390469\n",
      "  0.03316505 0.15114464 0.25376067 0.03742719 0.404091   0.05809909\n",
      "  0.19359091 0.03192398 0.03999618 0.07438015 0.5814734  0.31588697\n",
      "  0.11142016 0.07361227 0.12921715 0.07897162 0.06885285 0.06213598\n",
      "  0.08780362 0.10123809 0.05264601 0.05388097 0.04104769 0.13220108\n",
      "  0.08088591 0.0387916  0.04392844 0.02568184 0.01999819 0.02990619\n",
      "  0.04206051 0.02892715 0.1596701  0.15668266 0.0064509  0.32073084\n",
      "  0.05563845 0.03491526 0.11607295 0.13533945 0.05602363 0.09114408\n",
      "  0.18491618 0.02499918 0.0700933  0.05361593 0.01917134 0.01941978\n",
      "  0.08214372 0.11312409 0.2506411  0.05266577 0.02945919 0.09835785\n",
      "  0.06119109 0.16271345 0.01964159 0.0440129  0.25562802 0.41600525\n",
      "  0.06802373 0.0325596  0.11914217 0.155519   0.18486428 0.67310774\n",
      "  0.08704491 0.02360469 0.0539116  0.06989636 0.1307575  0.05441475\n",
      "  0.12794018 0.40890667 0.23326713 0.03894847 0.06145993 0.24472612\n",
      "  0.23526567 0.01833331 0.05594069 0.09805303 0.03406268 0.04173438\n",
      "  0.11512405 0.2436731  0.02981123 0.35655037 0.27449834 0.02261827\n",
      "  0.05580843 0.05788101 0.07837096 0.61852133 0.04956551 0.64916295\n",
      "  0.07208931 0.0821387  0.09095337 0.13986962 0.03979273 0.0801492\n",
      "  0.29440805 0.42684296 0.40428862 0.06246659 0.20374751 0.09711181\n",
      "  0.04976726 0.43540755 0.06214271 0.18954355 0.19196688 0.27542296\n",
      "  0.06963336 0.533653   0.17791659 0.06616739 0.11183199 0.05325919\n",
      "  0.14070794 0.05961614 0.02239522 0.1975466  0.23090413 0.0535512\n",
      "  0.08310906 0.17898928 0.17017943 0.09102703 0.13041292 0.09090526\n",
      "  0.02155171 0.10309912 0.09178616 0.11715198 0.10643142 0.00393729\n",
      "  0.04927673 0.04746468 0.5676147  0.05799781 0.12816943 0.14449342\n",
      "  0.09573038 0.6910339  0.0921824  0.14785068 0.18160537 0.1738042\n",
      "  0.149824   0.07498244 0.0294261  0.09724781 0.07520842 0.34179756\n",
      "  0.15415807 0.06437975 0.02621682 0.07162149 0.0594753  0.07366863\n",
      "  0.0201397  0.06761276 0.07198252 0.17253837 0.07465906 0.02486613\n",
      "  0.2541108  0.16489528 0.12280964 0.12213486 0.10049068 0.15930456\n",
      "  0.12324669 0.06618541 0.12413843 0.23893009 0.03759822 0.05146993\n",
      "  0.187562   0.02189928 0.08496742 0.05438008 0.02792517 0.33626992\n",
      "  0.03045276 0.13447891 0.7930222  0.0315958  0.02904301 0.4703368\n",
      "  1.3704855  0.2554178  0.08960429 0.09991866 0.2837553  0.2503853\n",
      "  0.09412799 0.10101847 0.11678671 0.4295147  0.0161639  0.08341688\n",
      "  0.14330268 0.05962438 0.04023783 0.0464239  0.11232398 0.5921917\n",
      "  0.07900891 0.01385238 0.08285912 0.12669204 0.04760249 0.02035089\n",
      "  0.06504941 0.04723671 0.03305707 0.13732319 0.06573854 0.15957993\n",
      "  0.04364803 0.28896168 0.06772472 0.05665512 0.09791696 0.10040677\n",
      "  0.26800528 0.02893846 0.44876716 0.07982439 0.11030287 0.06838675\n",
      "  0.07794206 0.08257903 0.18480928 0.49900663 0.10967938 0.06036672\n",
      "  0.35389525 0.11362302 0.08179238 0.10803583 0.10208531 0.21150126\n",
      "  0.02778276 0.15126479 0.49719125 0.04881243 0.5678329  0.18443926\n",
      "  0.03989445 0.07652413 0.12855236 0.14099577 0.148166   0.1300478\n",
      "  0.17694752 0.21371883 0.06396704 0.08377382 0.05550787 0.01891547\n",
      "  0.14740086 0.03796613 0.06668771 0.03627472 0.2422753  0.01475509\n",
      "  0.03838125 0.04840781 0.0611209  0.09440152 0.06218266 0.08462552\n",
      "  0.10576529 0.10564575 0.02572497 0.0430215  0.3440747  0.06273875\n",
      "  0.22977135 0.14889681 0.04319932 0.03010912 0.08147227 0.2290349\n",
      "  0.11463325 0.04984106 0.24128398 0.10470754 0.02275158 0.18145172\n",
      "  0.03541673 0.10227112 0.0218971  0.04149647 0.2610831  0.0225487\n",
      "  0.09565658 0.10231431 0.38876608 0.09847879 0.25201395 0.02838442\n",
      "  0.00359181 0.07441148 0.10365435 0.06269928 0.19841704 0.27790946\n",
      "  0.12120999 0.13683602 0.05459827 0.02641925 0.09249876 0.13074969\n",
      "  0.07665054 0.04109454 0.1585382  0.04448661 0.11110467 0.08916071\n",
      "  0.12370934 0.05577246 0.17715093 0.04356754 0.19557835 0.05230333\n",
      "  0.05613479 0.02238132 0.45625657 0.18320164 0.22360802 0.1595848\n",
      "  0.13452339 0.1447833  0.09413243 0.01237519 0.11349971 0.32046968\n",
      "  0.14297567 0.0910051  0.10697167 0.19137016 0.07655632 0.05126519\n",
      "  1.3120583  0.219326   0.10080308 0.16875471 0.36443734 0.26999792\n",
      "  0.20025894 0.13274927 0.15994412 0.38170686 0.4109534  0.05568504\n",
      "  0.03068106 0.16098692 0.16176333 0.12334643 0.02184071 0.2070402\n",
      "  0.13028589 0.17211254 0.2176513  0.4497587  0.21665344 0.02509288\n",
      "  0.06721985 0.29907688 0.13050506 0.09220129 0.18700816 0.11281058\n",
      "  0.08061463 0.05907566 0.04803506 0.10005463 0.08537042 0.23084916\n",
      "  0.21605583 0.05070742 0.05768891 0.79753846 0.0534665  0.04154418\n",
      "  0.04280204 0.06201566 0.20824045 0.12589669 0.08824001 0.05851242\n",
      "  0.19270843 0.35303202 0.26145568 0.08342779 0.17616469 0.04986335\n",
      "  0.35243422 0.11435358 0.05161494 0.07958448 0.02751656 0.19176888\n",
      "  0.38088644 0.0677769  0.05451082 0.16494498 0.09520428 0.13129699\n",
      "  0.03924388 0.2760999  0.20746398 0.11729178 0.06027738 0.00775377\n",
      "  0.0619607  0.11311243 0.0287008  0.34008896 0.03291422 0.05519104\n",
      "  0.05385222 0.25221395 0.21408133 0.1603065  0.08189322 0.06842588\n",
      "  0.39313748 0.255925   0.5211812  0.02945934 0.16302797 0.03202178\n",
      "  0.02977354 0.03437878 0.06073014 0.04023732 0.35044265 0.06147819\n",
      "  0.08543864 0.14651242 0.0615814  0.04236999 0.03524642 0.4967062\n",
      "  0.02420747 0.03611077 0.05080664 0.07660811 0.02035058 0.4243257\n",
      "  0.22811893 0.14542165 0.05768485 0.15248549 0.10056362 0.05881414\n",
      "  0.09910151 0.20200755 0.14060065 0.2631314  0.01627581 0.11561813\n",
      "  0.30810547 0.06272765 0.1814653  0.02591288 0.09047031 0.18836743\n",
      "  0.06491838 0.04215364 0.13001265 0.05378354 0.23317441 0.09541997\n",
      "  0.21487279 1.2177144  0.14312102 0.41635045 0.1042736  0.06362835\n",
      "  0.35741106 0.10284881 0.03137315 0.04684066 0.21584526 0.47494912\n",
      "  0.03810211 0.11814771 0.04438819 0.106691   0.18373919 0.22158739\n",
      "  0.12244394 0.10465799 0.25623527 0.01069787 0.04349506 0.06599259\n",
      "  0.25305817 0.18553896 0.05251487 0.53301907 0.685806   0.01944607\n",
      "  0.434937   0.0431939  0.02163366 0.04208804 0.06479174 0.05490575\n",
      "  0.1248493  0.13672876 0.38403025 0.02964444 0.263943   0.06616258\n",
      "  0.04175137 0.11189152 0.07592478 0.05775604 0.10033192 0.07765765\n",
      "  0.03891    0.13727601 0.02085982 0.07609808 0.09434482 0.12900376\n",
      "  0.34246543 0.04877644 0.04640041 0.2538237  0.18052836 0.33160368\n",
      "  0.31977865 0.21469395 0.07557889 0.15240397 0.09330821 0.12639067\n",
      "  0.03077003 0.06742398 0.07711705 0.04477376 0.05704636 0.05944909\n",
      "  0.05012839 0.14924626 0.0525824  0.04473683 0.0404853  0.2223488\n",
      "  0.1015892  0.16084565 0.11001929 0.02681217 0.19448929 0.05661595\n",
      "  0.24663205 0.15080567 0.18618822 0.09330843 0.09277093 0.6403748\n",
      "  0.0710263  0.07112348 0.03678011 0.31424794 0.07568202 0.0206789\n",
      "  0.20095941 0.04005942 0.07545869 0.08904096 0.0570954  0.10294005\n",
      "  0.02981819 0.09090659 0.07646894 0.095115   0.12897292 0.07446062\n",
      "  0.0991073  0.3797654  0.1120868  0.2619761  0.12418467 0.1007191\n",
      "  0.3246085  0.14697161 0.07377072 0.07674208 0.08690554 0.15950276\n",
      "  0.13920024 0.54421526 0.07261348 0.0540598  0.03972331 0.05828935\n",
      "  0.06829239 0.16519181 0.08028872 0.05969624 0.23037863 0.18123822\n",
      "  0.08599413 0.0311986  0.15241262 0.04463433 0.09692259 0.05585883\n",
      "  0.13487735 0.00924026 0.05521098 0.06336326 0.1200629  0.05504908\n",
      "  0.03750905 0.14942752 0.16728787 0.25035292 0.60435504 0.25163278\n",
      "  0.05627693 0.69920176 0.3698508  0.01001861 0.0809692  0.02894858\n",
      "  0.04369145 0.20312671 0.0154405  0.03877096 0.30311036 0.10447672\n",
      "  0.03712753 0.10334194 0.02442104 0.44795185 0.18097354 0.11044899\n",
      "  0.02575812 0.01479233 0.16817741 0.14162558 0.03666551 0.02567019\n",
      "  0.70648474 0.1338533  0.0255835  0.24169558]]\n"
     ]
    }
   ],
   "source": [
    "# Generate some dummy input data\n",
    "# dummy_input = tf.random.normal((1, 1, 28))\n",
    "\n",
    "data = [2.700e-01, 1.600e-01, 1.600e-01, 0.000e+00, 0.000e+00, 0.000e+00,\n",
    "0.000e+00, 0.000e+00, 3.450e+00, 2.005e+01, 5.810e-02, 1.300e-01, 4.300e-01,\n",
    "3.300e-01, 2.780e+00, 8.420e-02, 2.000e-02, 2.000e-02, 1.000e-02,\n",
    "1.500e-01, 3.220e+00, 3.553e+00, 4.300e-01]\n",
    "input = np.array(data)        \n",
    "reshaped_single_sample = input.reshape(1, -1) # Reshapes to (1, number_of_features)\n",
    "print(reshaped_single_sample.shape)\n",
    "\n",
    "# Get the output of the final layer\n",
    "final_layer_output = model.predict(reshaped_single_sample)\n",
    "print(reshaped_single_sample)\n",
    "final_layer_output = final_layer_output*100\n",
    "print(final_layer_output)\n",
    "\n",
    "# smallest = final_layer_output[0]\n",
    "# for val in final_layer_output:\n",
    "#     if val < smallest:\n",
    "#         smallest = val\n",
    "# print(smallest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
