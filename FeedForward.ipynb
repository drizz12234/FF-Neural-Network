{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faac2b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Setup\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import pathlib, os, sys, operator, re, datetime\n",
    "\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Model\n",
    "import tensorflow_datasets as tfds\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f0699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Fantasy\n",
      "1          PPR\n",
      "2        355.3\n",
      "3        336.4\n",
      "4        362.9\n",
      "        ...   \n",
      "627         -2\n",
      "628         -2\n",
      "629       -2.4\n",
      "630       -2.1\n",
      "631       -2.7\n",
      "Name: Column28, Length: 632, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data2018 = 'p:\\Mitchell\\FFNeuralNetwork\\stats2018.csv'\n",
    "data2019 = 'p:\\Mitchell\\FFNeuralNetwork\\stats2019.csv'\n",
    "data2020 = 'p:\\Mitchell\\FFNeuralNetwork\\stats2020.csv'\n",
    "data2021 = 'p:\\Mitchell\\FFNeuralNetwork\\stats2021.csv'\n",
    "data2022 = 'p:\\Mitchell\\FFNeuralNetwork\\stats2022.csv'\n",
    "data2023 = 'p:\\Mitchell\\FFNeuralNetwork\\stats2023.csv'\n",
    "data2024 = 'p:\\Mitchell\\FFNeuralNetwork\\stats2024.csv'\n",
    "\n",
    "rank2018 = pd.read_csv(data2018)\n",
    "H_2018 = rank2018.shape[0]\n",
    "finish_2018 = np.array([H_2018])\n",
    "finish_2018 = rank2018[\"Column2\"]\n",
    "ppr_2018 = rank2018[\"Column28\"]\n",
    "\n",
    "rank2019 = pd.read_csv(data2019)\n",
    "H_2019 = rank2019.shape[0]\n",
    "finish_2019 = np.array([H_2019])\n",
    "finish_2019 = rank2019[\"Column2\"]\n",
    "ppr_2019 = rank2019[\"Column28\"]\n",
    "\n",
    "rank2020 = pd.read_csv(data2020)\n",
    "H_2020 = rank2020.shape[0]\n",
    "finish_2020 = np.array([H_2020])\n",
    "finish_2020 = rank2020[\"Column2\"]\n",
    "ppr_2020 = rank2020[\"Column28\"]\n",
    "\n",
    "rank2021 = pd.read_csv(data2021)\n",
    "H_2021 = rank2021.shape[0]\n",
    "finish_2021 = np.array([H_2021])\n",
    "finish_2021 = rank2021[\"Column2\"]\n",
    "ppr_2021 = rank2021[\"Column28\"]\n",
    "\n",
    "rank2022 = pd.read_csv(data2022)\n",
    "H_2022 = rank2022.shape[0]\n",
    "finish_2022 = np.array([H_2022])\n",
    "finish_2022 = rank2022[\"Column2\"]\n",
    "ppr_2022 = rank2022[\"Column28\"]\n",
    "\n",
    "rank2023 = pd.read_csv(data2023)\n",
    "H_2023 = rank2023.shape[0]\n",
    "finish_2023 = np.array([H_2023])\n",
    "finish_2023 = rank2023[\"Column2\"]\n",
    "ppr_2023 = rank2023[\"Column28\"]\n",
    "\n",
    "rank2024 = pd.read_csv(data2024)\n",
    "H_2024 = rank2024.shape[0]\n",
    "finish_2024 = np.array([H_2024])\n",
    "finish_2024 = rank2024[\"Column2\"]\n",
    "ppr_2024 = rank2024[\"Column28\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "184e6d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['227' '286.5' '265.4' '282.5' '207.2' '232.7' '182.5' '403.2' '149.7'\n",
      " '282.4' '230.3' '190.7' '199.4' '167.3' '243.7' '0' '135.4' '267.7' '0'\n",
      " '0' '218.6' '246.7' '190.2' '208.8' '75.2' '164.4' '146.4' '113.1'\n",
      " '150.5' '0' '177.1' '106.4' '225.4' '295.6' '342.8' '319.1' '0' '0'\n",
      " '376.4' '391.3' '331.2' '199.3' '0' '89.3' '40.2' '262.7' '35' '94'\n",
      " '212.5' '141.8' '128.8' '165' '211.2' '181.1' '290.5' '117.6' '46.2'\n",
      " '147.2' '249.2' '203.2' '229.9' '30.4' '250.2' '124.8' '298.5' '392.6'\n",
      " '179.2' '0' '223.2' '50.9' '241.1' '187' '280.2' '223.6' '201.2' '230.2'\n",
      " '1' '0' '267' '231.3' '256.9' '233' '195.5' '0' '156.4' '257.5' '132.1'\n",
      " '243.1' '260.4' '107.5' '209.2' '0' '155.6' '202.2' '107.2' '276' '174.4'\n",
      " '19.8' '68.3' '78.5' '255' '0' '246.3' '100' '41' '85' '152.7' '234.2'\n",
      " '330.9' '219.4' '150.3' '5.3' '134.9' '106' '185.4' '227.6' '60.8' '95.7'\n",
      " '289.6' '71.6' '118.5' '0' '153.8' '0' '196.4' '222.6' '213.9' '145.7'\n",
      " '200.7' '53.5' '202.4' '209.2' '69.9' '206.4' '231' '239.3' '177.1' '0'\n",
      " '0' '72.7' '173.2' '60.3' '198.6' '161.4' '156.4' '39.2' '115.5' '273.8'\n",
      " '22.2' '65.4' '134.7' '102' '49.1' '0' '73.9' '126.8' '121.3' '79.5' '80'\n",
      " '45.2' '60.4' '6.2' '143.5' '0' '144.8' '289.1' '39.7' '150.3' '52.7'\n",
      " '87.3' '0' '169.6' '133.2' '219' '4.8' '34.8' '73' '89' '217.2' '91.5'\n",
      " '78.9' '174.5' '109.3' '97.1' '38.5' '100.8' '40' '101.6' '0' '50.3' '0'\n",
      " '37.9' '0' '270.4' '44.2' '37.2' '0' '119.9' '84.4' '0' '201.5' '39.7'\n",
      " '69.2' '23.4' '106.1' '110.2' '6.3' '39.9' '144.4' '0' '22.6' '124.2'\n",
      " '136.3' '64.5' '133.2' 'nan' '47.5' '21.7' '101.1' '87.4' '356.8' '5.2'\n",
      " '27.2' '82.7' '20.3' '40.2' '0' '12.7' '67.6' '125.8' '278.9' '24.9'\n",
      " '48.5' '221.3' '181.5' '274.1' '119.9' '0' '112.5' '57.9' '0' '242.1'\n",
      " '116.5' '0' '198.1' '97.4' '35.7' '108.5' '0' '127.4' '71.8' '0' '0' '0'\n",
      " '26' '267.9' '64.1' '22.9' '0' '51.5' '19.3' '6.7' '53.3' '95.4' '13'\n",
      " '60.1' '53.7' '213.2' '16.9' '43.5' 'PPR' '137.6' '58.8' '25.6' 'nan'\n",
      " '10.9' '227.3' '23.5' '0' '50.6' '42.8' '-0.1' '0' '4.8' '0' '33.5'\n",
      " '59.7' '22.8' '0' '0' '0' '70.6' '0' '21.5' '101' '35.9' '48.4' '39.1'\n",
      " '10.6' '48.7' '30' 'nan' '174.4' '157.1' '7.5' '8.1' '9.7' '43.1' '54.6'\n",
      " '0' '114.5' '57' '113.4' '119.8' '23.1' '93.5' '196.2' '24.4' '46.7'\n",
      " '10.6' '0' '0' '67.1' '105' '73.4' '0' '149.8' '5.5' 'nan' '123.1' '24.9'\n",
      " 'nan' '0' '28.5' '0' '4.7' '71.4' '0' '46.3' '48.7' '72.4' '38.7' '0' '0'\n",
      " '42.9' '62' '0' '0' '0' '78.1' '1.6' '32.5' '0' '28.5' '14.7' '46.9'\n",
      " '44.7' '60.6' '11.1' 'nan' '14' '31.1' '40.3' '157.2' '0' '0' '20.4' '0'\n",
      " '13.9' '5.9' '36.4' '101.3' '0' '0' 'nan' '14.5' 'nan' '20.1' '0' 'nan'\n",
      " '6.2' '19' '10.2' '21.3' '12.9' '0' '28.5' '0' '0' '86.8' '37.8' '13.6'\n",
      " '137.3' '0' '0' '3.1' '0' '0' '15.8' '12' '11.6' '5.5' '0' '56.9' '76.8'\n",
      " '36.3' '0' '0' 'nan' '26.6' '0' '30' '53.3' '25.5' '7.9' '23.6' '0'\n",
      " '33.9' '62.6' '28.1' '0' '106.7' '0' '0' '33.5' '112.4' '60.4' '1.2'\n",
      " '97.8' '3.1' '15.8' '29.6' '0' '0' '30.8' '12.4' '4' '21.9' '80.2' '0'\n",
      " '61.7' '21.5' '0' '53' '3.1' '20.3' '32.5' 'nan' '2.2' '113.2' '2.1'\n",
      " '12.8' '0' '20.7' '0' '10.3' '0' '0' '0' '0' '0' '56.5' '37.9' '6.8'\n",
      " '9.3' '0' '66.7' 'nan' '0' '0' '0' '41.3' '0' '36.9' '17.8' '0' '26.1'\n",
      " 'nan' 'nan' '0' '0' '0' '58.7' '2.2' '0' '0' '0' '0' '2' '4.9' '0' '0'\n",
      " 'nan' '35.2' '0' '0' 'nan' '8.2' '0' '9.9' '0' '3.1' '0' '0' 'nan' 'nan'\n",
      " '39.6' '0' '87.8' '1.7' '0' '0' '47.2' '0' '0' '0' '97.4' '0' '0' '0' '0'\n",
      " '26.5' '0' '27' '4.8' '10.6' '-2' '11.2' '0' '0' '3.1' '0' '0' '0' '61.7'\n",
      " '0' '29.1' '61' '6.4' '11.6' '0' '181.1' 'nan' '0' 'nan' '7.9' '0' '0'\n",
      " '21.7' '45.9' '40.2' '1.9' 'nan' 'nan' 'nan' '1.9' '0' '0' '51.7' 'nan'\n",
      " '1.6' '14' '0' '8.8' '0' '2.1' '8.8' '0' '0' '73.4' '0' '10' 'nan' '19.4'\n",
      " '0' 'nan' '0' '0' '0' '4.9' '69.6' '69.6' '43.3' '0' '3.6' '0' '3' '0'\n",
      " '-0.4' '1' '5.9' '0' '0' '9.9' 'nan' '0' '0' '31.1' '16.6' '19' '3.3' '0'\n",
      " '16.2' 'nan' '5.9' '0' '23' '8.8' '0' '1.3' '0' 'nan' '0' '0' '0' '13.1'\n",
      " '0' 'nan' '0' '-0.2' '15' '0' '0' 'nan' '262.5' '0' '3.3' '25.6' '11.1'\n",
      " '0']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "update2024 = np.empty((0,0))\n",
    "print(update2024)\n",
    "for h in range(2, H_2024):\n",
    "    player2024 = finish_2024[h]\n",
    "    for i in range(2, H_2023):\n",
    "        player2023 = finish_2023[i]\n",
    "        if(player2024 == player2023):\n",
    "            # update2024 = np.append(update2024, [i-1])\n",
    "            update2024 = np.append(update2024, ppr_2023[i-1])\n",
    "            break\n",
    "        if(i == H_2023 -1):\n",
    "            update2024 = np.append(update2024, [0])\n",
    "\n",
    "print(update2024)\n",
    "\n",
    "update2023 = np.empty((0,0))\n",
    "print(update2023)\n",
    "for h in range(2, H_2023):\n",
    "    player2023 = finish_2023[h]\n",
    "    for i in range(2, H_2022):\n",
    "        player2022 = finish_2022[i]\n",
    "        ppr2022 = ppr_2022[i]\n",
    "        if(player2023 == player2022):\n",
    "            # update2023 = np.append(update2023, [i-1])\n",
    "            update2023 = np.append(update2023, ppr_2022[i-1])\n",
    "            break\n",
    "        if(i == H_2022 -1):\n",
    "            update2023 = np.append(update2023, [0])\n",
    "\n",
    "update2022 = np.empty((0,0))\n",
    "print(update2022)\n",
    "for h in range(2, H_2022):\n",
    "    player2022 = finish_2022[h]\n",
    "    for i in range(2, H_2021):\n",
    "        player2021 = finish_2021[i]\n",
    "        ppr2021 = ppr_2021[i]\n",
    "        if(player2022 == player2021):\n",
    "            # update2022 = np.append(update2022, [i-1])\n",
    "            update2022 = np.append(update2022, ppr_2021[i-1])\n",
    "            break\n",
    "        if(i == H_2021 -1):\n",
    "            update2022 = np.append(update2022, [0])\n",
    "\n",
    "update2021 = np.empty((0,0))\n",
    "print(update2021)\n",
    "for h in range(2, H_2021):\n",
    "    player2021 = finish_2021[h]\n",
    "    for i in range(2, H_2020):\n",
    "        player2020 = finish_2020[i]\n",
    "        ppr2020 = ppr_2020[i]\n",
    "        if(player2021 == player2020):\n",
    "            # update2021 = np.append(update2021, [i-1])\n",
    "            update2021 = np.append(update2021, ppr_2020[i-1])\n",
    "            break\n",
    "        if(i == H_2020 -1):\n",
    "            update2021 = np.append(update2021, [0])\n",
    "\n",
    "update2020 = np.empty((0,0))\n",
    "print(update2020)\n",
    "for h in range(2, H_2020):\n",
    "    player2020 = finish_2020[h]\n",
    "    for i in range(2, H_2019):\n",
    "        player2019 = finish_2019[i]\n",
    "        ppr2019 = ppr_2019[i]\n",
    "        if(player2020 == player2019):\n",
    "            # update2020 = np.append(update2020, [i-1])\n",
    "            update2020 = np.append(update2020, ppr_2019[i-1])\n",
    "            break\n",
    "        if(i == H_2019 -1):\n",
    "            update2020 = np.append(update2020, [0])\n",
    "\n",
    "update2019 = np.empty((0,0))\n",
    "print(update2019)\n",
    "for h in range(2, H_2019):\n",
    "    player2019 = finish_2019[h]\n",
    "    for i in range(2, H_2018):\n",
    "        player2018 = finish_2018[i]\n",
    "        ppr2018 = ppr_2018[i]\n",
    "        if(player2019 == player2018):\n",
    "            # update2019 = np.append(update2019, [i-1])\n",
    "            update2019 = np.append(update2019, ppr_2018[i-1])\n",
    "            break\n",
    "        if(i == H_2018 -1):\n",
    "            update2019 = np.append(update2019, [0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2c6624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2024 = pd.DataFrame(update2024)\n",
    "df2024.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2024\")\n",
    "# df2023 = pd.DataFrame(update2023)\n",
    "# df2023.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2023\")\n",
    "# df2022 = pd.DataFrame(update2022)\n",
    "# df2022.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2022\")\n",
    "# df2021 = pd.DataFrame(update2021)\n",
    "# df2021.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2021\")\n",
    "# df2020 = pd.DataFrame(update2020)\n",
    "# df2020.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2020\")\n",
    "# df2019 = pd.DataFrame(update2019)\n",
    "# df2019.to_excel('p:\\Mitchell\\statsPrevYear.xlsx', index=False, sheet_name = \"2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3652b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3246, 1, 19)\n",
      "[[0.00155279]\n",
      " [0.00310559]\n",
      " [0.00465839]\n",
      " ...\n",
      " [0.9968355 ]\n",
      " [0.99841774]\n",
      " [1.        ]]\n"
     ]
    }
   ],
   "source": [
    "data = 'p:\\Mitchell\\FFNeuralNetwork\\statsTraining.csv'\n",
    "dataAns = 'p:\\Mitchell\\FFNeuralNetwork\\statsAnswer.csv'\n",
    "\n",
    "Smalldata = 'p:\\Mitchell\\FFNeuralNetwork\\SmallBatchTraining.csv'\n",
    "SmalldataAns = 'p:\\Mitchell\\FFNeuralNetwork\\SmallBatchTrainingAns.csv'\n",
    "\n",
    "regular = True \n",
    "\n",
    "if(regular):\n",
    "    df = pd.read_csv(data)\n",
    "    df_y = pd.read_csv(dataAns)\n",
    "\n",
    "    numpy_array = df.to_numpy()\n",
    "    numpy_array = numpy_array[:, np.newaxis, :]\n",
    "    numpy_size = numpy_array.size\n",
    "\n",
    "    numpy_array_two = df_y.to_numpy()\n",
    "    numpy_array_two = numpy_array_two.astype(np.float32)\n",
    "\n",
    "    numpy_array[np.isnan(numpy_array)] = 0\n",
    "    numpy_array_test = numpy_array.astype(np.float32)\n",
    "\n",
    "    # print(numpy_array)\n",
    "    # print(numpy_size)\n",
    "    # print(numpy_array.shape)\n",
    "    # print(numpy_array_two.shape)\n",
    "else:\n",
    "    df = pd.read_csv(Smalldata)\n",
    "    df_y = pd.read_csv(SmalldataAns)\n",
    "\n",
    "    numpy_array = df.to_numpy()\n",
    "    numpy_array = numpy_array[:, np.newaxis, :]\n",
    "    numpy_size = numpy_array.size\n",
    "\n",
    "    numpy_array_two = df_y.to_numpy()\n",
    "    numpy_array_two = numpy_array_two.astype(np.float32)\n",
    "\n",
    "    numpy_array[np.isnan(numpy_array)] = 0\n",
    "    numpy_array_test = numpy_array.astype(np.float32)\n",
    "\n",
    "    # print(numpy_array)\n",
    "    # print(numpy_size)\n",
    "    # print(numpy_array.shape)\n",
    "    # print(numpy_array_two.shape) \n",
    "\n",
    "H = numpy_array.shape[0]\n",
    "W = numpy_array.shape[1]\n",
    "\n",
    "H2 = numpy_array_two.shape[0]\n",
    "W2 = numpy_array_two.shape[1]\n",
    "\n",
    "numpy_array = numpy_array/100\n",
    "numpy_array_two = numpy_array_two\n",
    "\n",
    "print(numpy_array.shape)\n",
    "# print(numpy_array)   \n",
    "print(numpy_array_two)   \n",
    "\n",
    "# print(H)\n",
    "# print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5096ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630, 1, 19)\n"
     ]
    }
   ],
   "source": [
    "Testdata = 'p:\\Mitchell\\FFNeuralNetwork\\statsTesting.csv'\n",
    "TestdataAns = 'p:\\Mitchell\\FFNeuralNetwork\\statsTestAnswer.csv'\n",
    "\n",
    "SmallTestdata = 'p:\\Mitchell\\FFNeuralNetwork\\SmallBatchTest.csv'\n",
    "SmallTestdataAns = 'p:\\Mitchell\\FFNeuralNetwork\\SmallBatchTestAns.csv'\n",
    "\n",
    "regular = True \n",
    "\n",
    "if(regular):\n",
    "    Testdf = pd.read_csv(Testdata)\n",
    "    Testdf_y = pd.read_csv(TestdataAns)\n",
    "\n",
    "    numpy_array_test = Testdf.to_numpy()\n",
    "    numpy_array_test = numpy_array_test[:, np.newaxis, :]\n",
    "    numpy_sizeT = numpy_array_test.size\n",
    "\n",
    "    numpy_array_ans = Testdf_y.to_numpy()\n",
    "    numpy_array_ans = numpy_array_ans.astype(np.float32)\n",
    "\n",
    "    numpy_array_test[np.isnan(numpy_array_test)] = 0\n",
    "    numpy_array_test = numpy_array_test.astype(np.float32)\n",
    "else:\n",
    "    Testdf = pd.read_csv(SmallTestdata)\n",
    "    Testdf_y = pd.read_csv(SmallTestdataAns)\n",
    "\n",
    "    numpy_array_test = Testdf.to_numpy()\n",
    "    numpy_array_test = numpy_array_test[:, np.newaxis, :]\n",
    "    numpy_sizeT = numpy_array_test.size\n",
    "\n",
    "    numpy_array_ans = Testdf_y.to_numpy()\n",
    "    numpy_array_ans = numpy_array_ans.astype(np.float32)\n",
    "\n",
    "    numpy_array_test[np.isnan(numpy_array_test)] = 0\n",
    "    numpy_array_test = numpy_array_test.astype(np.float32)\n",
    "\n",
    "\n",
    "HT = numpy_array_test.shape[0]\n",
    "WT = numpy_array_test.shape[1]\n",
    "\n",
    "HT2 = numpy_array_ans.shape[0]\n",
    "WT2 = numpy_array_ans.shape[1]\n",
    "\n",
    "numpy_array_test = numpy_array_test/100\n",
    "numpy_array_ans = numpy_array_ans/(numpy_array_ans.size)\n",
    "    \n",
    "print(numpy_array_test.shape)\n",
    "# print(numpy_array_test)\n",
    "# print(numpy_array_ans)\n",
    "\n",
    "# print(H)\n",
    "# print(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8918 - loss: 0.3636 - val_accuracy: 0.9660 - val_loss: 0.1109\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.0978 - val_accuracy: 0.9752 - val_loss: 0.0836\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0660 - val_accuracy: 0.9770 - val_loss: 0.0770\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0528 - val_accuracy: 0.9804 - val_loss: 0.0667\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0425 - val_accuracy: 0.9776 - val_loss: 0.0717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ad95731810>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow Example\n",
    "\n",
    "\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28), name='layers_input'),\n",
    "    tf.keras.layers.Flatten(name='layers_flatten'),\n",
    "    tf.keras.layers.Dense(512, activation='relu', name='layers_dense'),\n",
    "    tf.keras.layers.Dropout(0.2, name='layers_dropout'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name='layers_dense_2')\n",
    "  ])\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f7b219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3297 - val_loss: 0.3331\n",
      "Epoch 2/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3314 - val_loss: 0.3331\n",
      "Epoch 3/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3370 - val_loss: 0.3331\n",
      "Epoch 4/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3407 - val_loss: 0.3331\n",
      "Epoch 5/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3287 - val_loss: 0.3331\n",
      "Epoch 6/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3276 - val_loss: 0.3331\n",
      "Epoch 7/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3322 - val_loss: 0.3331\n",
      "Epoch 8/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3370 - val_loss: 0.3331\n",
      "Epoch 9/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3404 - val_loss: 0.3331\n",
      "Epoch 10/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3309 - val_loss: 0.3331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2873ef02010>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  # tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1000, activation='softmax')\n",
    "])\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#   loss='sparse_categorical_crossentropy',\n",
    "#   metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "  loss='mean_squared_error')\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# print(numpy_array[1,0])\n",
    "# model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "model.fit(numpy_array, numpy_array_two, epochs=10, validation_data=(numpy_array_test, numpy_array_ans), callbacks=[tensorboard_callback])\n",
    "# model.evaluate(numpy_array_test, numpy_array_ans, verbose = 2)\n",
    "\n",
    "# python -m tensorboard.main --logdir=logs/fit\n",
    "\n",
    "# Use above to view data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a44aa691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 23)\n"
     ]
    }
   ],
   "source": [
    "# Generate some dummy input data\n",
    "# dummy_input = tf.random.normal((1, 1, 28))\n",
    "\n",
    "data = [2.700e-01, 1.600e-01, 1.600e-01, 0.000e+00, 0.000e+00, 0.000e+00,\n",
    "0.000e+00, 0.000e+00, 3.450e+00, 2.005e+01, 5.810e-02, 1.300e-01, 4.300e-01,\n",
    "3.300e-01, 2.780e+00, 8.420e-02, 2.000e-02, 2.000e-02, 1.000e-02,\n",
    "1.500e-01, 3.220e+00, 3.553e+00, 4.300e-01]\n",
    "input = np.array(data)        \n",
    "reshaped_single_sample = input.reshape(1, -1) # Reshapes to (1, number_of_features)\n",
    "print(reshaped_single_sample.shape)\n",
    "\n",
    "# Get the output of the final layer\n",
    "# final_layer_output = model.predict(reshaped_single_sample)\n",
    "# print(reshaped_single_sample)\n",
    "# final_layer_output = final_layer_output*100\n",
    "# print(final_layer_output)\n",
    "\n",
    "# smallest = final_layer_output[0]\n",
    "# for val in final_layer_output:\n",
    "#     if val < smallest:\n",
    "#         smallest = val\n",
    "# print(smallest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
